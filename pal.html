<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Personalized Active Learner</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- TODO: Find a way to cache fonts from Google as they are resource heavy -->
    <link href='https://fonts.googleapis.com/css?family=Lato:100,300,400,700,900' rel='stylesheet' type='text/css'>
    <link href="https://fonts.googleapis.com/css?family=Montserrat:300,600,700" rel="stylesheet">
    <link rel="stylesheet" type="text/css" media="screen" href="css/project.css" />
</head>

<body style="margin: 0;">
    <main class="border">
        <section>
            <article class="unresponsive">
                <div class="project-title">
                    PAL
                </div>

            </article>
            <article class="unresponsive">
                <a href="/#work">
                    <img style="width: 4rem; float: right;" src="assets/clear.svg">
                </a>

            </article>
        </section>


        <section>
            <article class="content">
                <!-- TODO: Make the text more spaced apart and easier to read -->
                <b>Personalized Active Learner (PAL) </b> is a closed-loop, contextually-aware, personalized and user-centric <span class="bold"> wearable device </span> which leverages Artificial Intelligence and Biotechnology for Memory Augmentation, Language Learning, and Behavior
                Change.
                <br> 
                <br>
                PAL aims to enable people to design their lives (i.e. inspire behavior change) to optimize their cognitive, physical, and emotional well-being. People's actions deeply influence their internal and external bodily states, which
in turn reinforces their own actions. PAL aims to help people to be aware of the correlations between their different
activities and internal states so that behavioral awareness can drive <span class="bold"> intrinsically motivated behavior change. </span>
            </article>
            <!-- TODO: Make this table mobile-responsive -->
            <article class="table">
                <span class="header">PROJECT DETAILS</span>
                <div>
                    <div class="item-block">
                        <span class="title">Year</span>
                        <span class="value">June 2018 - Jan 2019</span>
                    </div>
                </div>
                <div>
                    <div class="item-block">
                        <span class="title">Scope</span>
                        <span class="value">AI, Wearable computing, Biotechnology</span>
                    </div>
                </div>
                <div>
                    <div class="item-block">
                        <span class="title">Link</span>
<span class="value"><a href="https://www.media.mit.edu/projects/pal/overview/" class="style-link">https://www.media.mit.edu/projects/pal/overview</a></span>
                    </div>
                </div>
                <div>
                    
                </div>
            </article>
        </section>
        <!-- Let the following section touch the viewport borders
        so that the images look bigger and better -->
        <!-- <div class="cell">
                <img src="assets/PAL.png" class="responsive-image">
            </div> -->
        <section class="gutterless">
            <article>
                <img src="assets/pal_device.jpg" class="responsive-image">


            </article>
            <article>
                <img src="assets/pal_design.png" class="responsive-image">


            </article>

        </section>
        <!-- TODO: Since the content is arranged in a story format. Animations can bring them in
        sequentially. -->
        <section class="content">
            <article>
I was in charge of the Artificial Intelligence aspect of the 'PAL' project. Since I was working with wearable computing, I had to adhere to a unique set of constraints: <span class="bold">low compute, fewer data
and less memory space. </span>
<br>
<ul>
<li> To overcome the low compute I employed special USB-type Neural Accelerators to run the machine learning and designed my
Neural Network models to be smaller and run faster. I was able to achieve <span class="bold"> real-time, offline and on-device face
recognition </span> on the wearable system. </li>
<li> I devised a <i>one-shot</i> machine learning technique to easily onboard new user faces with just a single picture
without retraining the whole model every time. Onboarding now takes about <span class="bold"> 2 seconds on an offline, low-power embedded
device.</span> </li>
</ul>
This now allows the wearable to provide real-time memory assistance <span class="bold"> (Memory Augmentation) </span> using
personalized face
recognition to recognize and remind people of persons in their social circle.
            </article>
        </section>
<section class="gutterless">
    <article class="center">
        <img src="assets/face_rec.png" class="responsive-image">
    </article>
</section>
<section class="content">
    <article>
I was also in charge of the <span class="bold"> software pipelining </span> in the PAL project.
<br>
I built a modular wearable architecture called <span class="bold">PiWear</span> which allows for rapid-prototyping of
wearable experiments involving data collection, processing, and machine learning. I designed it to be <span class="bold"> highly modular </span> so that researchers
after me can easily add or remove modules to suit their experiment setting.
PiWear is currently being used in the PAL project for Memory augmentation, Language Learning and Activity recognition.
I also led the software team with an iterative process of development, deploy, and feedback which allowed us to demo fully
functional prototypes of Memory Augmentation and Language Learning to Bose and Members' week.
</article>
</section>
<section class="gutterless">
    <article class="center">
        <img src="assets/ll.png" class="responsive-image">
    </article>
<article class="center">
    <img src="assets/obj_detect.png" class="responsive-image">
</article>
</section>
<section class="content">
    <article>
I also designed <span class="bold">superfast and offline object recognition</span> for the wearable device. I was able
to achieve a frame rate of 9 fps. This enables the wearable to use real-time object detection to enable contextual <i>Language Learning </i> in the real world so
that the users can learn new languages in a mobile and contextual setting.
<br> <br>
I am also working on a novel <span class="bold">Activity Recognition classifier</span> that works in a way similar to
how humans classify their
own activities.
Activity recognition can be used by the wearable to keep track of a person's daily activities in order to frame
effective interventions or record important attributes like <span class="bold">sleep, productivity and exercise time
</span> to gain a better insight into the
user's mental and physical state and thereby, advance general well being and increase self-awareness.
            </article>
        </section>
        <section class="gutterless">
            <article class="center">
                <img src="assets/activity_rec.png" class="responsive-image">
            </article>
        </section>

        <!-- TODO: Add more pictures -->
        <!-- TODO: Add masonryjs for perfect grid pictures -->


    </main>


</body>

</html>